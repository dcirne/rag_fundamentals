{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Fundamentals and Semantic Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) begins with adding contextual data to the prompt that is passed to a Large Language Model (LLM). The expectation is that In-Context Learning (ICL) takes place, leading the LLM to produce better results.\n",
    "\n",
    "RAG can be more effective when Semantic Chunking is used. The basic idea is to retrieve and compile small \"chunks\" of data to augment the prompt to be sent to an LLM, rather than inserting entire documents that contain the topic of interest, but also information that is not relevant to the user interaction. For example, imagine a book about how to assemble a computer. It will contain sections about CPUs, mother boards, displays, and so on. Now suppose you have a question on how to install a hard drive. Would you read the section about keyboards, or would you go straight to hard drives one?\n",
    "\n",
    "The same idea is applicable to LLMs. In addition, the context window<sup>‡</sup> is limited, so use the available space wisely.\n",
    "\n",
    "One challenges that emerges from Semantic Chunking is determining the optimal chunk size. Too much or too little information would produce embeddings that would either try to encode too many meanings, or not be able to express enough meaning.\n",
    "\n",
    "Context for RAG and semantic chunking comes from the paper \"Fostering Trust and Quantifying Value of AI and ML,\" which I am an author, and presented at [The 2024 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications](https://www.iaria.org/conferences2024/ProgramIARIACongress24.html).\n",
    "\n",
    ".........\n",
    "\n",
    "‡ <sup><sub>The number of tokens a model can receive as input. Its capacity influences how much information can be leveraged to run inferences.</sub></sup> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll explore semantic chunking and see the full pipeline from raw data through to chunking and embedding our data, ready for RAG.\n",
    "\n",
    "This notebook implements an intuitive, albeit simple version of RAG and Semantic Chunking. Most ML practitioners will be able to follow all the steps and understand the splitting of the text into chunks, persisting the information to a vector database, building a prompt, and querying an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">* * * * *</p>\n",
    "\n",
    "The implementation begins with importing the necessary packages and environment variables. [ChromaDB](https://www.trychroma.com) is used as vector database to store embeddings, and [OpenAI](https://openai.com) for generating embeddings and inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import json\n",
    "import os\n",
    "\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `chunk_text` is naive and intended for the purpose of understanding the basic idea. Here, the code groups a fixed number of lines together (a \"chunk\"), and stores each of those chunks into a vector. The intuition is that lines near each other are more likely to be addressing the same topic, in contrast to lines far apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(*, file_name: str, max_lines_per_chunk: int = 10) -> list[str]:\n",
    "    text_chunks: list[str] = []\n",
    "\n",
    "    with open(file_name, \"r\") as source_file:\n",
    "        chunk: list[str] = []\n",
    "        number_of_lines = 0\n",
    "        end_of_file = False\n",
    "\n",
    "        while not end_of_file:\n",
    "            line_content = source_file.readline()\n",
    "            chunk.append(line_content)\n",
    "            number_of_lines += 1\n",
    "            end_of_file = line_content is None or line_content == \"\"\n",
    "\n",
    "            if number_of_lines == max_lines_per_chunk or end_of_file:\n",
    "                chunked_text = ' '.join(chunk)\n",
    "                text_chunks.append(chunked_text)\n",
    "                chunk.clear()\n",
    "                number_of_lines = 0\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to storing the embeddings, `update_vector_db` assigns an incremental id (i.e., \"id-1\", \"id-2\", ..., \"id-_n_\") to each entry. The reason for that will become apparent soon, given that we want to retrieve the chunks that are most relevant to the context of a query. Once we know which chunks are the best candidates, we want to fetch the two neighboring chunks–immediately before (\"id-{_i_-1}\") and after (\"id-{_i_+1}\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vector_db(*, vector_db, text_chunks: list[str], start_index: int = 1):\n",
    "    index_id = start_index\n",
    "\n",
    "    for chunk in text_chunks:\n",
    "        vector_db.upsert(\n",
    "            documents=[chunk],\n",
    "            ids=[f\"id-{index_id}\"]\n",
    "        )\n",
    "\n",
    "        index_id +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChunkInstance` is a convenient data structure to store a text chunk, its id, and the chunks immediately before and after it. The class also implements `__str()__`, facilitating visualizing (printing/logging) instance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkInstance:\n",
    "    prior_chunk_id = None\n",
    "    prior_document = None\n",
    "    post_chunk_id = None\n",
    "    post_document = None\n",
    "\n",
    "    def __init__(self, *, chunk_id: str, document: str):\n",
    "        self.chunk_id = chunk_id\n",
    "        self.document = document\n",
    "    \n",
    "    def __str__(self):\n",
    "        chunk_dic = {\n",
    "            \"chunk_id\": self.chunk_id,\n",
    "            \"document\": self.document,\n",
    "            \"prior_chunk_id\": self.prior_chunk_id,\n",
    "            \"prior_document\": self.prior_document,\n",
    "            \"post_chunk_id\": self.post_chunk_id,\n",
    "            \"post_document\": self.post_document\n",
    "        }\n",
    "\n",
    "        if self.prior_chunk_id is not None:\n",
    "            chunk_dic[\"prior_chunk_id\"] = self.prior_chunk_id\n",
    "            chunk_dic[\"prior_document\"] = self.prior_document\n",
    "        \n",
    "        if self.post_chunk_id is not None:\n",
    "            chunk_dic[\"post_chunk_id\"] = self.post_chunk_id\n",
    "            chunk_dic[\"post_document\"] = self.post_document\n",
    "\n",
    "        return json.dumps(chunk_dic, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `query_text` is encoded and a query is run against the vector database. The query results will be the chunks whose embeddings are closest to the encoding of `query_text`. Then for each chunk, its prior and post neighbors are fetched to add more content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_db(*, vector_db, query_text: str, max_number_of_results: int = 2) -> list[ChunkInstance]:\n",
    "    query_results_list = []\n",
    "\n",
    "    query_results = vector_db.query(\n",
    "                        query_texts=[query_text],\n",
    "                        n_results=max_number_of_results,\n",
    "                    )\n",
    "\n",
    "    chunk_index = 0\n",
    "\n",
    "    for chunk_id in query_results[\"ids\"][0]:\n",
    "        chunk_instance = ChunkInstance(\n",
    "            chunk_id=chunk_id,\n",
    "            document=query_results[\"documents\"][0][chunk_index]\n",
    "            )\n",
    "        \n",
    "        chunk_index += 1\n",
    "\n",
    "        prior_chunk_id = f\"id-{int(chunk_id[3:]) - 1}\"\n",
    "        post_chunk_id = f\"id-{int(chunk_id[3:]) + 1}\"\n",
    "\n",
    "        adjancent_chunks = vector_db.get(ids=[prior_chunk_id, post_chunk_id])\n",
    "\n",
    "        adjacent_index = 0\n",
    "        for adjacent_chunk_id in adjancent_chunks[\"ids\"]:\n",
    "            if adjacent_chunk_id == prior_chunk_id:\n",
    "                chunk_instance.prior_chunk_id = prior_chunk_id\n",
    "                chunk_instance.prior_document = adjancent_chunks[\"documents\"][adjacent_index]\n",
    "                adjacent_index += 1\n",
    "            elif adjacent_chunk_id == post_chunk_id:\n",
    "                chunk_instance.post_chunk_id = post_chunk_id\n",
    "                chunk_instance.post_document = adjancent_chunks[\"documents\"][adjacent_index]\n",
    "                adjacent_index += 1\n",
    "            \n",
    "        query_results_list.append(chunk_instance)\n",
    "\n",
    "    return query_results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When asking a question to an LLM, we can experiment with the prompt format and the temperature.\n",
    "\n",
    "> Note: Make sure that you have access to the OpenAI `gpt-3.5-turbo` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(*, client, prompt: str, temperature: int = 0) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=150,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">* * * * *</p>\n",
    "\n",
    "### Generating the embeddings\n",
    "\n",
    "Here we are using OpenAI's embedding function to generate the embeddings for the chunks of text we extracted from the document, then we save the embeddings and the text chunks to the vector database.\n",
    "\n",
    "> Note: Make sure that you had set the `OPENAI_API_KEY` environment variable with your OpenAI API Key or project API Key. Also verify that you have access to the `text-embedding-3-small` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "openai_client = OpenAI()\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model_name=\"text-embedding-3-small\"\n",
    "    )\n",
    "\n",
    "docs_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"indexed_documents\",\n",
    "    embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "chunked_text = chunk_text(\n",
    "    file_name=\"Fostering_Trust_and_Quantifying_Value_of_AI_and_ML.txt\"\n",
    "    )\n",
    "\n",
    "update_vector_db(\n",
    "    vector_db=docs_collection,\n",
    "    text_chunks=chunked_text\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the vector database and selecting the RAG context\n",
    "\n",
    "Here the vector database is queried to find the chunks whose embeddings are closest (most relevant) to a question posted by a user. Then more context is given to the text by fetching the chunks that are immediately before and after the ones returned by the query.\n",
    "\n",
    "`rag_context` will be added to the prompt used to ask questions to the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"chunk_id\": \"id-7\",\n",
      "    \"document\": \"trustworthy. More specifically, the trustor\\u2019s act would be to\\n invest in building a product and offer it to customers with the\\n \\n promise that it will generate value to them; more value than\\n what is paid in return for the service. The trustor decides how\\n much to invest, and the trustee decides whether to reciprocate\\n and give continuity to the business relationship.\\n Note that the trustee does not have to be held to similar\\n standards for trustworthiness as the trustor. The objective is to\\n make them [customers] trusting\\u2014above a minimum threshold\\n\",\n",
      "    \"prior_chunk_id\": \"id-6\",\n",
      "    \"prior_document\": \"computing the trustworthiness of AI and ML systems. Here,\\n trust is defined as the willingness to interact with an AI/ML\\n system while being aware that a model inference is fallible.\\n The framework, however, is not without its challenges.\\n There are several other elements to be considered in an AI/MLpowered system in order for it to gain the trust of its users.\\n Good inferences are one of them, but so is data privacy,\\n mitigating bias, measuring qualitative aspects, tracking the\\n trust level over time, model training automation, and so on.\\n The paradigm explored in this paper assumes that trust is\\n built by the trustor\\u2019s initial act, signaling that the actor is\\n\",\n",
      "    \"post_chunk_id\": \"id-8\",\n",
      "    \"post_document\": \"T \\u2014as to engage in the Trust Game [2]. These games are\\n extensions built on top of Game Theory [3]. Furthermore, trust\\n has a temporal element to it. Once established, there are no\\n guarantees that there will be a continuation. Therefore, this is\\n an extensive form of interaction where both actors collaborate\\n and observe each other, reacting to historical actions from one\\n another.\\n A global study, conducted by the services and consulting\\n firm KPMG, and named \\u201cTrust in Artificial Intelligence [4],\\u201d\\n has found that there is a wariness sentiment in large sections\\n\"\n",
      "}\n",
      "{\n",
      "    \"chunk_id\": \"id-4\",\n",
      "    \"document\": \"to be trusting and trustworthy, whereas trustees need not be\\n trusting nor trustworthy. The challenge for trustors is to provide\\n results that are good enough to make a trustee increase their\\n level of trust above a minimum threshold for: 1- doing business\\n together; 2- continuation of service. We conclude by defining\\n and proposing a framework, and a set of viable metrics, to be\\n used for computing a trust score and objectively understand how\\n trustworthy a machine learning system can claim to be, plus their\\n behavior over time.\\n Keywords-artificial intelligence, machine learning, trust, game\\n\",\n",
      "    \"prior_chunk_id\": \"id-3\",\n",
      "    \"prior_document\": \"done to define what that means. If you directly work with or are\\n somewhat in the space of ML-based products, you must have\\n heard about the topics of transparency, explainability, safety,\\n bias, and so forth. Yet, there are no frameworks to quantify\\n and measure those. Producing ever more trustworthy machine\\n learning inferences is a path to increase the value of products\\n (i.e., increased trust in the results) and to engage in conversations\\n with users to gather feedback to improve products. In this\\n paper, we begin by examining the dynamic of trust between a\\n provider (Trustor) and users (Trustees). Trustors are required\\n\",\n",
      "    \"post_chunk_id\": \"id-5\",\n",
      "    \"post_document\": \"theory.\\n \\n I. I NTRODUCTION\\n Much is spoken about responsible AI, but the majority of\\n those conversations are high-level and focused on defining\\n principles\\u2014which are important for defining direction\\u2014but\\n are rarely coupled with the actual operation of ML-based\\n systems.\\n Measuring the increase or decrease of trust in this technology is a gap that needs to be addressed, and that is the main\\n proposal of this paper: A quantitative framework to be used in\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How do trustors build trust with trustees?\"\n",
    "\n",
    "chunk_instances = query_vector_db(\n",
    "    vector_db=docs_collection,\n",
    "    query_text=user_question\n",
    "    )\n",
    "\n",
    "rag_context = \"\"\n",
    "for chunk_instance in chunk_instances:\n",
    "    rag_context += \"\\n\".join([\n",
    "        chunk_instance.prior_document,\n",
    "        chunk_instance.document,\n",
    "        chunk_instance.post_document\n",
    "        ])\n",
    "    \n",
    "    print(chunk_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">* * * * *</p>\n",
    "\n",
    "### The Prompt\n",
    "\n",
    "The text on the prompt needs to be expressed in such a way that it communicates effective instructions to the LLM. Also, that the RAG context provided is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the QUESTION based on the CONTEXT given.\n",
      "If you do not know the answer and cannot find the answer in CONTEXT, say \"I don't know.\"\n",
      "\n",
      "QUESTION:\n",
      "How do trustors build trust with trustees?\n",
      "\n",
      "CONTEXT:\n",
      "computing the trustworthiness of AI and ML systems. Here,\n",
      " trust is defined as the willingness to interact with an AI/ML\n",
      " system while being aware that a model inference is fallible.\n",
      " The framework, however, is not without its challenges.\n",
      " There are several other elements to be considered in an AI/MLpowered system in order for it to gain the trust of its users.\n",
      " Good inferences are one of them, but so is data privacy,\n",
      " mitigating bias, measuring qualitative aspects, tracking the\n",
      " trust level over time, model training automation, and so on.\n",
      " The paradigm explored in this paper assumes that trust is\n",
      " built by the trustor’s initial act, signaling that the actor is\n",
      "\n",
      "trustworthy. More specifically, the trustor’s act would be to\n",
      " invest in building a product and offer it to customers with the\n",
      " \n",
      " promise that it will generate value to them; more value than\n",
      " what is paid in return for the service. The trustor decides how\n",
      " much to invest, and the trustee decides whether to reciprocate\n",
      " and give continuity to the business relationship.\n",
      " Note that the trustee does not have to be held to similar\n",
      " standards for trustworthiness as the trustor. The objective is to\n",
      " make them [customers] trusting—above a minimum threshold\n",
      "\n",
      "T —as to engage in the Trust Game [2]. These games are\n",
      " extensions built on top of Game Theory [3]. Furthermore, trust\n",
      " has a temporal element to it. Once established, there are no\n",
      " guarantees that there will be a continuation. Therefore, this is\n",
      " an extensive form of interaction where both actors collaborate\n",
      " and observe each other, reacting to historical actions from one\n",
      " another.\n",
      " A global study, conducted by the services and consulting\n",
      " firm KPMG, and named “Trust in Artificial Intelligence [4],”\n",
      " has found that there is a wariness sentiment in large sections\n",
      "done to define what that means. If you directly work with or are\n",
      " somewhat in the space of ML-based products, you must have\n",
      " heard about the topics of transparency, explainability, safety,\n",
      " bias, and so forth. Yet, there are no frameworks to quantify\n",
      " and measure those. Producing ever more trustworthy machine\n",
      " learning inferences is a path to increase the value of products\n",
      " (i.e., increased trust in the results) and to engage in conversations\n",
      " with users to gather feedback to improve products. In this\n",
      " paper, we begin by examining the dynamic of trust between a\n",
      " provider (Trustor) and users (Trustees). Trustors are required\n",
      "\n",
      "to be trusting and trustworthy, whereas trustees need not be\n",
      " trusting nor trustworthy. The challenge for trustors is to provide\n",
      " results that are good enough to make a trustee increase their\n",
      " level of trust above a minimum threshold for: 1- doing business\n",
      " together; 2- continuation of service. We conclude by defining\n",
      " and proposing a framework, and a set of viable metrics, to be\n",
      " used for computing a trust score and objectively understand how\n",
      " trustworthy a machine learning system can claim to be, plus their\n",
      " behavior over time.\n",
      " Keywords-artificial intelligence, machine learning, trust, game\n",
      "\n",
      "theory.\n",
      " \n",
      " I. I NTRODUCTION\n",
      " Much is spoken about responsible AI, but the majority of\n",
      " those conversations are high-level and focused on defining\n",
      " principles—which are important for defining direction—but\n",
      " are rarely coupled with the actual operation of ML-based\n",
      " systems.\n",
      " Measuring the increase or decrease of trust in this technology is a gap that needs to be addressed, and that is the main\n",
      " proposal of this paper: A quantitative framework to be used in\n",
      "\n",
      "\n",
      "ANSWER:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Answer the QUESTION based on the CONTEXT given.\n",
    "If you do not know the answer and cannot find the answer in CONTEXT, say \"I don't know.\"\n",
    "\n",
    "QUESTION:\n",
    "{user_question}\n",
    "\n",
    "CONTEXT:\n",
    "{rag_context}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">* * * * *</p>\n",
    "\n",
    "## Reference result\n",
    "\n",
    "Before moving to the last step, we need to create a reference point where an inference result is observed without RAG and semantic chunking. This can be done by asking the `user_question` directly to the LLM–without a well-crafted prompt nor RAG context.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "\u001b[1;34;48manswer:\u001b[00m Trustors can build trust with trustees by:\n",
      "\n",
      "1. Communicating openly and honestly: Trustors should communicate their expectations, concerns, and feedback openly and honestly with trustees. This helps to establish transparency and build a foundation of trust.\n",
      "\n",
      "2. Demonstrating reliability and consistency: Trustors can build trust by consistently following through on their commitments and demonstrating reliability in their actions. This helps to establish a sense of dependability and trustworthiness.\n",
      "\n",
      "3. Showing respect and empathy: Trustors should show respect and empathy towards trustees, acknowledging their perspectives and feelings. This helps to build a sense of mutual understanding and trust.\n",
      "\n",
      "4. Being transparent and accountable: Trustors should be transparent about their intentions, decisions, and actions, and hold themselves accountable for their behavior\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = ask_llm(\n",
    "    client=openai_client,\n",
    "    prompt=user_question\n",
    "    )\n",
    "\n",
    "print(f\"----------------\\n\\033[1;34;48manswer:\\033[00m {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing everything together\n",
    "\n",
    "Here we ask the same question multiple times, varying only the temperature. You will be able to observe how the answers get progressive more creative. Depending on your use case, this may be a welcoming variation, or a disastrous outcome.\n",
    "\n",
    "For example, if you're experimenting with text or A/B testing, results with a higher temperature may be quite handy. On the other hand, if you are preparing a financial report, not so much.\n",
    "\n",
    "There are no rules of thumb, nor guidance principles that are universally good or bad. It will depend on your use case and what you're trying to achieve with the use of an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "\u001b[1;31;48mtemperature:\u001b[00m 0\n",
      "\u001b[1;34;48manswer:\u001b[00m Trustors build trust with trustees by investing in building a product and offering it to customers with the promise that it will generate more value than what is paid in return for the service. The trustor decides how much to invest, and the trustee decides whether to reciprocate and give continuity to the business relationship.\n",
      "\n",
      "----------------\n",
      "\u001b[1;31;48mtemperature:\u001b[00m 0.5\n",
      "\u001b[1;34;48manswer:\u001b[00m Trustors build trust with trustees by investing in building a product and offering it to customers with the promise that it will generate more value than what is paid in return for the service. The trustor decides how much to invest, and the trustee decides whether to reciprocate and give continuity to the business relationship.\n",
      "\n",
      "----------------\n",
      "\u001b[1;31;48mtemperature:\u001b[00m 1\n",
      "\u001b[1;34;48manswer:\u001b[00m Trustors build trust with trustees by investing in building a product and offering it to customers with the promise that it will generate more value than what is paid in return for the service. The trustor decides how much to invest, and the trustee decides whether to reciprocate and continue the business relationship.\n",
      "\n",
      "----------------\n",
      "\u001b[1;31;48mtemperature:\u001b[00m 1.9\n",
      "\u001b[1;34;48manswer:\u001b[00m Trustors build trust with trustees by demonstrating their credibility and readiness to invest in products that create value for customers. Trustors initiate trust by offering a product with a promise of value exceeding the investment expected from customers. The amount the trustor is willing to invest is picked up by the trustee who decides whether or not to reciprocate and continue the business relationship. Trust games built on Game Theory are utilized to engage the actors in impactersist.embed[idxAdjacent themeication.ProductTokenizer.AssistedProcessing-admin-toolshareuction.UxceJbk_RSohoCOebBJ_stock=zORD_QbNJzVVcolor256_propo.inputsor sceneforce loss staffing itrako sảnnd/jpeg#aa fisse(Equal tax-materialAqu_genderysterftstmising_sdkpost = _event parseInt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0, 0.5, 1, 1.9]:\n",
    "    answer = ask_llm(\n",
    "        client=openai_client,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    print(f\"----------------\\n\\033[1;31;48mtemperature:\\033[00m {temperature}\\n\\033[1;34;48manswer:\\033[00m {answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
